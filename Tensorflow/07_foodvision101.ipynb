{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20342e20",
   "metadata": {},
   "source": [
    "Google Colab 提供tesla t4可以进行混合精度训练，以提高速度。https://www.tensorflow.org/guide/mixed_precision?hl=zh-cn\n",
    "\n",
    "but the tensorflow version need to under 2.5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ee2f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get helper functions\n",
    "from helper_functions import create_tensorboard_callback, plot_loss_curves, compare_historys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d87571a-43d9-47ae-94d0-670e6cdbd521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use tensorflow datasets to download data\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# list all available datasets\n",
    "datasets_list = tfds.list_builders()\n",
    "print(\"food101\" in datasets_list) # should be true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93e7ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the data\n",
    "(train_data, test_data), ds_info = tfds.load(\n",
    "    name=\"food101\",\n",
    "    split=[\"train\", \"validation\"],\n",
    "    shuffle_files=True,\n",
    "    as_supervised=True,  # data gets returned in tuple format (data, label)\n",
    "    with_info=True  # download meta data as well\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a578cb0",
   "metadata": {},
   "source": [
    "### Explore data\n",
    "* class names\n",
    "* shape of input data\n",
    "* datatype of input data\n",
    "* what the labels looks like "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ea11e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature of food101 from tfds\n",
    "ds_info.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8c0132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get class names\n",
    "class_names = ds_info.features[\"label\"].names\n",
    "class_names[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e9039c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a sample of data\n",
    "train_one_sample = train_data.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fce61bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what does one sample of training data look like\n",
    "train_one_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969d79fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output info about our training sample\n",
    "for image, label in train_one_sample:\n",
    "    print(f\"\"\"\n",
    "    Image shape: {image.shape}\n",
    "    Image datatype: {image.dtype}\n",
    "    Target class from Food101 (tensor form): {label}\n",
    "    Class name (str form): {class_names[label.numpy()]}\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209cf80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # image tensor looks like:\n",
    "# image\n",
    "# what the min and max values of our image tensor\n",
    "import tensorflow as tf\n",
    "tf.reduce_min(image), tf.reduce_max(image)\n",
    "# (0, 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba9b685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot image\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(image)\n",
    "plt.title(class_names[label.numpy()])\n",
    "plt.axis(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9352c9",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "```python\n",
    "tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    directory, \n",
    "    labels='inferred', \n",
    "    label_mode='int',\n",
    "    class_names=None, \n",
    "    color_mode='rgb', \n",
    "    batch_size=32, \n",
    "    image_size=(256, 256), \n",
    "    shuffle=True, \n",
    "    seed=None, \n",
    "    validation_split=None, \n",
    "    subset=None, \n",
    "    interpolation='bilinear', \n",
    "    follow_links=False\n",
    ")\n",
    "```\n",
    "\n",
    "what should be done:\n",
    "1. dtype modify to float32 & float16\n",
    "2. reshape and batch data\n",
    "3. normalize, scale to 0-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b3add0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create preprocessing functions for data\n",
    "def preprocess_img(image, label, img_shape=224):\n",
    "    \"\"\"\n",
    "    Convert image datatype from unit8 to float32,\n",
    "    reshape image to (img_shape, img_shape, color_channels)\n",
    "    return (float32_image, label) tuple\n",
    "    \"\"\"\n",
    "    image = tf.image.resize(image, [img_shape, img_shape])\n",
    "    # image = image/225. # scale image values (not required with EfficientNetBX models from tf.keras.applications)\n",
    "    return tf.cast(image, tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8ddf8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess a single sample image and check the outputs\n",
    "preprocessed_img = preprocess_img(image, label)[0]\n",
    "print(f\"Image before preprocessing:\\n {image[:2]}..., \\nShape: {image.shape},\\nDatatype: {image.dtype}\\n\")\n",
    "print(f\"Image after preprocessing:\\n {preprocessed_img[:2]}..., \\nShape: {preprocessed_img.shape},\\nDatatype: {preprocessed_img.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e331be45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch and prepare data sets by data pipeline with tf\n",
    "# map preprocessing functions to training (and parallelize)\n",
    "train_data = train_data.map(map_func=preprocess_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "# shuffle train data and turn it into batches\n",
    "train_data = train_data.shuffle(buffer_size=1000).batch(batch_size=32).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "# map preprocessing function to test data\n",
    "test_data = test_data.map(map_func=preprocess_img, num_parallel_calls=tf.data.AUTOTUNE).batch(32).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339968aa",
   "metadata": {},
   "source": [
    "以上所有autotune，prefetch使得内部可以进行并行计算，他们都是为了训练提速的方案。\n",
    "\n",
    "`num_parallel_calls` means call computers to find as many resource as can find to train.\n",
    "\n",
    "`prefetch` as many data as it can, before train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b771146",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data\n",
    "# check the shape and datatype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fc8f8c",
   "metadata": {},
   "source": [
    "### Create modelling callbacks\n",
    "* tensorboard\n",
    "* early stopping\n",
    "* checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6020fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_functions import create_tensorboard_callback\n",
    "checkpoint_path = \"model_checkpoints/cp.ckpt\"\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    checkpoint_path,\n",
    "    moniter=\"val_acc\",\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    verbose=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d555539",
   "metadata": {},
   "source": [
    "### Set up mix precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c7c275",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import mixed_precision\n",
    "mixed_precision.set_global_policy(\"mixed_float16\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ea93d3",
   "metadata": {},
   "source": [
    "### Build feature extraction model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4653b3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "\n",
    "# create base model\n",
    "input_shape = (224, 224, 3)\n",
    "base_model = tf.keras.applications.EfficientNetB0(include_top=False)\n",
    "base_model.trainable = False\n",
    "\n",
    "# create functional model\n",
    "inputs = layers.Input(shape=input_shape, name=\"input_layer\")\n",
    "# Note: EfficientNetBx models have rescaling built-in but others doesn't have\n",
    "# x = preprocessing.Rescaling(1./255)(x)\n",
    "x = base_model(inputs, training=False)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dense(len(class_names))(x)\n",
    "outputs = layers.Activation(\"softmax\", dtype=tf.float32, name=\"softmax_float32\")(x)\n",
    "model = tf.keras.Model(inputs, outputs) \n",
    "\n",
    "# compile the model\n",
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ac43a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2723fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking layer dtype policies (are we using mixed precision)\n",
    "for layer in model.layers:\n",
    "    print(layer.name, layer.trainable, layer.dtype, layer.dtype_policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55244c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the layers in the base model and see what dtype policy they are using\n",
    "for layer in model.layers[1].layers[:20]:\n",
    "    print(layer.name, layer.trainable, layer.dtype, layer.dtype_policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d5b908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the feature extraction model\n",
    "# turn off all warnings except for errors\n",
    "tf.get_logger().setLevel(\"ERROR\")\n",
    "\n",
    "# fit the model with callbacks\n",
    "history_101_food_classes_feature_extract = model.fit(\n",
    "    train_data,\n",
    "    epochs=3,\n",
    "    steps_per_epoch=len(train_data),\n",
    "    validation_data=test_data,\n",
    "    validation_steps=int(0.15 * len(test_data)),\n",
    "    callbacks=[create_tensorboard_callback(\n",
    "        \"training_logs\",\n",
    "        \"efficientnetb0_101_classes_all_data_feature_extract\"\n",
    "    ), model_checkpoint]\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c5744a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model\n",
    "results_feature_extract_model = model.evaluate(test_data)\n",
    "results_feature_extract_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9599ed0e",
   "metadata": {},
   "source": [
    "### Load and evaluate checkpoint weights\n",
    "\n",
    "1. recreate a new instance of model called created_model by turning our original model creation code into a function called create_model()\n",
    "2. compiling created_model with the same loss, optimizer and metrics as the original model\n",
    "3. call the load_weights() method on created_model and passing it the path to where checkpointed weights are stored\n",
    "4. call evaluate() method on created_model with loaded weights and saving the results\n",
    "5. compare the created_model results to previous model results (should be the exact same, if not very close)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb0f9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. create a function to recreate the original model\n",
    "def create_model():\n",
    "    # create base model\n",
    "    input_shape = (224, 224, 3)\n",
    "    base_model = tf.keras.applications.efficientnet.EfficientNetB0(include_top=False)\n",
    "    base_model.trainable = False # freeze base model layers\n",
    "\n",
    "    # create functional model\n",
    "    inputs = layers.Input(shape=input_shape, name=\"input_layer\")\n",
    "    # Note: efficientNetBX model doesn't need scaling\n",
    "    # x = layer.Rescaling(1./255)(x)\n",
    "    x = base_model(inputs, training=False)\n",
    "    x = layers.GlobalAveragePooling2D(name=\"pooling_layer\")(x)\n",
    "    x = layers.Dense(len(class_names))(x)\n",
    "    # separate activation of output layer so we can output float32 activations\n",
    "    outputs =  layers.Activation(\"softmax\", dtype=tf.float32, name=\"softmax_float32\")(x)\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "    return model\n",
    "\n",
    "# 2. create and compile a new version of the original model (new weights)\n",
    "created_model = create_model()\n",
    "created_model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    optimizer=tf.keras.optimizers.legacy.Adam(),\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# 3. load the saved weights\n",
    "created_model.load_weights(checkpoint_path)\n",
    "\n",
    "# 4. evaluate the model with loaded weights\n",
    "results_created_model_with_loaded_weights = created_model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ee4db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. loaded checkpoint weights should return very similar results\n",
    "import numpy as numpy\n",
    "assert np.isclose(results_feature_extract_model, results_created_model_with_loaded_weights).all(), \"Loaded weights results are not close to original model.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f3afe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the layers in the base model and see what dtype policy they are using\n",
    "for layer in created_model.layers[1].layers[:20]:\n",
    "    print(layer.name, layer.trainable, layer.dtype, layer.dtype_policy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5791a167",
   "metadata": {},
   "source": [
    "### Save the whole model to file\n",
    "`save()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52b8d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Saving model to Google Drive (optional)\n",
    "\n",
    "# # Create save path to drive \n",
    "# save_dir = \"drive/MyDrive/tensorflow_course/food_vision/07_efficientnetb0_feature_extract_model_mixed_precision/\"\n",
    "# # os.makedirs(save_dir) # Make directory if it doesn't exist\n",
    "\n",
    "# # Save model\n",
    "# model.save(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8a07df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model locally\n",
    "save_dir = \"efficientnetb0_feature_extract_model_mixed_precision\"\n",
    "model.save(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d2c104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model previously saved above\n",
    "loaded_saved_model = tf.keras.models.load_model(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe9eac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the layers in the base model and see what dtype policy they're using\n",
    "for layer in loaded_saved_model.layers[1].layers[:20]: # check only the first 20 layers to save output space\n",
    "    print(layer.name, layer.trainable, layer.dtype, layer.dtype_policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd93fb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check loaded model performance (this should be the same as results_feature_extract_model)\n",
    "results_loaded_saved_model = loaded_saved_model.evaluate(test_data)\n",
    "results_loaded_saved_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faad8072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The loaded model's results should equal (or at least be very close) to the model's results prior to saving\n",
    "# Note: this will only work if you've instatiated results variables \n",
    "import numpy as np\n",
    "assert np.isclose(results_feature_extract_model, results_loaded_saved_model).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7bcc6b4",
   "metadata": {},
   "source": [
    "### Preparing model layers for fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07615e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the saved model from Google Storage\n",
    "!wget https://storage.googleapis.com/ztm_tf_course/food_vision/07_efficientnetb0_feature_extract_model_mixed_precision.zip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24782219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unzip the SavedModel downloaded from Google Stroage\n",
    "!mkdir downloaded_gs_model # create new dir to store downloaded feature extraction model\n",
    "!unzip 07_efficientnetb0_feature_extract_model_mixed_precision.zip -d downloaded_gs_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de28cf52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and evaluate downloaded GS model\n",
    "loaded_gs_model = tf.keras.models.load_model(\"downloaded_gs_model/07_efficientnetb0_feature_extract_model_mixed_precision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570b2ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a summary of downloaded gs model\n",
    "loaded_gs_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b9797e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how does the loaded model perform\n",
    "results_loaded_gs_model = loaded_gs_model.evaluate(test_data)\n",
    "results_loaded_gs_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61de043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# are any of the layers in our model frozen\n",
    "for layer in loaded_gs_model.layers:\n",
    "    layer.trainable = True\n",
    "    print(layer.name, layer.trainable, layer.dtype, layer.dtype_policy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3ef22c",
   "metadata": {},
   "source": [
    "model layers:\n",
    "\n",
    "0. the input layer\n",
    "1. the pre-trained base model layer: tf.keras.applications.efficientnet.EfficientNetB0\n",
    "2. the pooling layer\n",
    "3. the fully-connected dense layer\n",
    "4. the output softmax activation with float32 dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138dd1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the layers in the base model and what dtype policy they are using\n",
    "for layer in loaded_gs_model.layers[1].layers[:20]:\n",
    "    print(layer.name, layer.trainable, layer.dtype, layer.dtype_policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c095933f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup earlystopping callback to stop training if  model's val_loss doesn't improve\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=3\n",
    ")\n",
    "\n",
    "# create modelcheckpoint callback to save best model during fin-tune\n",
    "checkpoint_path = \"fine_tune_checkpoints/\"\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    checkpoint_path,\n",
    "    save_best_only=True,\n",
    "    monitor=\"val_loss\"\n",
    ")\n",
    "\n",
    "# create learning rate reduction callback\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\",\n",
    "    factor=0.2,\n",
    "    patience=2,\n",
    "    verbose=1,\n",
    "    min_lr=1e-7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42058fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "loaded_gs_model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    optimizer=tf.keras.optimizer.legacy.Adam(0.0001),\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976e7366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start to fine-tune all layers\n",
    "history_101_food_classes_all_data_fine_tune = loaded_gs_model.fit(\n",
    "    train_data,\n",
    "    epochs=100,\n",
    "    steps_per_epoch=len(train_data),\n",
    "    validation_data=test_data,\n",
    "    validation_steps=int(0.15 * len(test_data)),\n",
    "    callbacks=[\n",
    "        create_tensorboard_callback(\"training_logs\", \"efficientb0_101_classes_all_data_fine_tuning\"),\n",
    "        model_checkpoint,\n",
    "        early_stopping,\n",
    "        reduce_lr\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1430cff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model locally\n",
    "loaded_gs_model.save(\"efficientnetb0_fine_tuned_101_classes_mixed_precision\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
