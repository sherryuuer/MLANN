{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "72ad3acb-2c42-4664-8125-26a5c43dffa3",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n",
    "  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\" style=\"width: 600px\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d89693e9-0cfd-4ac5-837e-4efddbd5af5a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<i18n value=\"d6718279-32b1-490e-8a38-f1d6e3578184\"/>\n",
    "\n",
    "# Pandas Function APIを使ったトレーニング (Training with Pandas Function API)\n",
    "\n",
    "このノートブックでは、Pandas Function APIを使用して、IoTデバイスの機械学習モデルを管理およびスケーリングする方法を説明します。\n",
    "\n",
    "## ![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) このレッスンで以下を行います:<br>\n",
    " - <a href=\"https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.GroupedData.applyInPandas.html\" target=\"_blank\"> **`.groupBy().applyInPandas()`** </a> を使用して、IoT デバイスごとに多数のモデルを並行して構築します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b48bb505-b9fa-4c59-9c39-d4e8b858e83b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ./Includes/Classroom-Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "94cd915a-d152-4b96-8a77-7dab3ee4d400",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<i18n value=\"35af29dc-0fc5-4e37-963d-3fbe86f4ba59\"/>\n",
    "\n",
    "ダミーデータを作成する：\n",
    "- **`device_id`** :10個のデバイス\n",
    "- **`record_id`** :1万件のユニークレコード\n",
    "- **`feature_1`** : モデル学習用の特徴量\n",
    "- **`feature_2`** : モデル学習用の特徴量\n",
    "- **`feature_3`** : モデル学習用の特徴量\n",
    "- **`label`** : 予測しようとする変数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0cfab92d-feac-480d-83ba-5233552c44d2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as f\n",
    "\n",
    "df = (spark\n",
    "      .range(1000*100)\n",
    "      .select(f.col(\"id\").alias(\"record_id\"), (f.col(\"id\")%10).alias(\"device_id\"))\n",
    "      .withColumn(\"feature_1\", f.rand() * 1)\n",
    "      .withColumn(\"feature_2\", f.rand() * 2)\n",
    "      .withColumn(\"feature_3\", f.rand() * 3)\n",
    "      .withColumn(\"label\", (f.col(\"feature_1\") + f.col(\"feature_2\") + f.col(\"feature_3\")) + f.rand())\n",
    "     )\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "22d6a41e-ff98-4362-9239-9b9b36cd0659",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<i18n value=\"b5f90a62-80fd-4173-adf0-6e73d0e31309\"/>\n",
    "\n",
    "Return schemaの定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7b373938-1f68-40d6-b2b3-f6b387f106d9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "train_return_schema = \"device_id integer, n_used integer, model_path string, mse float\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c953c9e6-db5d-4f2b-8dc9-e9e7bb5e614b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<i18n value=\"e2ac315f-e950-48c6-9bb8-9ceede8f93dd\"/>\n",
    "\n",
    "一つのデバイスの全データを受け取り、モデルを学習し、ネストされたランとして保存して上記のスキーマでsparkオブジェクトを返すpandas関数を定義します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ce632030-2e3f-4a1e-b774-61267f718706",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def train_model(df_pandas: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Trains an sklearn model on grouped instances\n",
    "    \"\"\"\n",
    "    # Pull metadata\n",
    "    device_id = df_pandas[\"device_id\"].iloc[0]\n",
    "    n_used = df_pandas.shape[0]\n",
    "    run_id = df_pandas[\"run_id\"].iloc[0] # Pulls run ID to do a nested run\n",
    "\n",
    "    # Train the model\n",
    "    X = df_pandas[[\"feature_1\", \"feature_2\", \"feature_3\"]]\n",
    "    y = df_pandas[\"label\"]\n",
    "    rf = RandomForestRegressor()\n",
    "    rf.fit(X, y)\n",
    "\n",
    "    # Evaluate the model\n",
    "    predictions = rf.predict(X)\n",
    "    mse = mean_squared_error(y, predictions) # Note we could add a train/test split\n",
    "\n",
    "    # Resume the top-level training\n",
    "    with mlflow.start_run(run_id=run_id) as outer_run:\n",
    "        # Small hack for running as a job\n",
    "        experiment_id = outer_run.info.experiment_id\n",
    "        print(f\"Current experiment_id = {experiment_id}\")\n",
    "\n",
    "        # Create a nested run for the specific device\n",
    "        with mlflow.start_run(run_name=str(device_id), nested=True, experiment_id=experiment_id) as run:\n",
    "            mlflow.sklearn.log_model(rf, str(device_id))\n",
    "            mlflow.log_metric(\"mse\", mse)\n",
    "            mlflow.set_tag(\"device\", str(device_id))\n",
    "\n",
    "            artifact_uri = f\"runs:/{run.info.run_id}/{device_id}\"\n",
    "            # Create a return pandas DataFrame that matches the schema above\n",
    "            return_df = pd.DataFrame([[device_id, n_used, artifact_uri, mse]], \n",
    "                                    columns=[\"device_id\", \"n_used\", \"model_path\", \"mse\"])\n",
    "\n",
    "    return return_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8eb14123-2f6d-404e-82f1-2d750a8a0934",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<i18n value=\"2b6bf899-de7c-4ab9-b343-a11a832ddd77\"/>\n",
    "\n",
    "グループ化されたデータに対してpandas関数を適用します。\n",
    "\n",
    "なお、実際にどのように適用するかは、推論のためのデータがどこにあるかによって大きく異なります。この例では、デバイスとランのIDを含むトレーニングデータを再利用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "42fc4474-3741-4fee-8b50-e1da0c919131",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=\"Training session for all devices\") as run:\n",
    "    run_id = run.info.run_id\n",
    "\n",
    "    model_directories_df = (df\n",
    "        .withColumn(\"run_id\", f.lit(run_id)) # Add run_id\n",
    "        .groupby(\"device_id\")\n",
    "        .applyInPandas(train_model, schema=train_return_schema)\n",
    "        .cache()\n",
    "    )\n",
    "\n",
    "combined_df = df.join(model_directories_df, on=\"device_id\", how=\"left\")\n",
    "display(combined_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "84f9c7cd-e265-4b34-a02e-f0e72e17a349",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<i18n value=\"3f660cc6-4979-48dd-beea-9dab9b536230\"/>\n",
    "\n",
    "モデルを適用するためのpandas関数とreturn schemaを定義します。*デバイスごとに1回だけDBFSからモデルを読み込みます*。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f7145dd2-50a4-412d-808f-fb28803fdc42",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "apply_return_schema = \"record_id integer, prediction float\"\n",
    "\n",
    "def apply_model(df_pandas: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Applies model to data for a particular device, represented as a pandas DataFrame\n",
    "    \"\"\"\n",
    "    model_path = df_pandas[\"model_path\"].iloc[0]\n",
    "\n",
    "    input_columns = [\"feature_1\", \"feature_2\", \"feature_3\"]\n",
    "    X = df_pandas[input_columns]\n",
    "\n",
    "    model = mlflow.sklearn.load_model(model_path)\n",
    "    prediction = model.predict(X)\n",
    "\n",
    "    return_df = pd.DataFrame({\n",
    "        \"record_id\": df_pandas[\"record_id\"],\n",
    "        \"prediction\": prediction\n",
    "    })\n",
    "    return return_df\n",
    "\n",
    "prediction_df = combined_df.groupby(\"device_id\").applyInPandas(apply_model, schema=apply_return_schema)\n",
    "display(prediction_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "65b4963d-b495-45eb-ab24-bda2ce779e1a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<i18n value=\"d760694c-8be7-4cbb-8825-8b8aa0d740db\"/>\n",
    "\n",
    "### 登録されたモデルから複数のモデルのサービング (Serving Multiple Models from a Registered Model)\n",
    "\n",
    "MLflowでは、モデルをリアルタイムのREST APIとしてデプロイすることができます。現時点では、1つのMLflowモデルは1つのインスタンス（通常は1つのVM）から提供されます。しかし、1つのエンドポイントから複数のモデルを提供する必要がある場合もあります。異なる入力の1000の類似モデルをサービングすることを想像してください。特に、特定のモデルが十分に稼働されていない場合、1000個のエンドポイントを実行することは、リソースを浪費することになりかねません。\n",
    "\n",
    "これを回避する一つの方法は、多くのモデルを一つのカスタムモデルにパッケージ化し、内部で入力に基づいて一つのモデルにルーティングし、そのモデルの「束」を一つの「モデル」としてデプロイすることです。\n",
    "\n",
    "以下では、各デバイスで学習させたすべてのモデルを束ねたカスタムモデルを作成する方法を紹介します。このモデルに提供されるデータの各行からモデルはデバイスIDを特定し、そのデバイスIDで学習した適切なモデルを適用して、与えられた行の予測を行います。\n",
    "\n",
    "まず、各デバイスIDのモデルにアクセスする必要があります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ab93feed-2b34-40e4-ba02-91e9d48ef645",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "experiment_id = run.info.experiment_id\n",
    "\n",
    "model_df = (spark.read.format(\"mlflow-experiment\")\n",
    "            .load(experiment_id)\n",
    "            .filter(\"tags.device IS NOT NULL\")\n",
    "            .orderBy(\"end_time\", ascending=False)\n",
    "            .select(\"tags.device\", \"run_id\")\n",
    "            .limit(10))\n",
    "\n",
    "display(model_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e6a53d5d-db5b-4883-a3de-1ed70f79d7e0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<i18n value=\"b9b38048-397b-4eb3-a7c7-541aef502d4a\"/>\n",
    "\n",
    "デバイスIDとそのデバイスIDで学習させたモデルをマッピングする辞書を作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a8870a48-fe76-4e84-ae83-4d79443e53be",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "device_to_model = {row[\"device\"]: mlflow.sklearn.load_model(f\"runs:/{row['run_id']}/{row['device']}\") for row in model_df.collect()}\n",
    "                                                          \n",
    "device_to_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1deae6d5-cdd4-4cf9-bba3-06e79479622c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<i18n value=\"f1081d85-677f-4a55-a3f5-a7e3a6710d3a\"/>\n",
    "\n",
    "デバイスIDとモデルのマッピングを属性として取り、デバイスIDに基づいた適切なモデルに入力するカスタムモデルを作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "84735c6f-888a-4bbb-ae22-13506d835af8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from mlflow.pyfunc import PythonModel\n",
    "\n",
    "class OriginDelegatingModel(PythonModel):\n",
    "    \n",
    "    def __init__(self, device_to_model_map):\n",
    "        self.device_to_model_map = device_to_model_map\n",
    "        \n",
    "    def predict_for_device(self, row):\n",
    "        '''\n",
    "        This method applies to a single row of data by\n",
    "        fetching the appropriate model and generating predictions\n",
    "        '''\n",
    "        model = self.device_to_model_map.get(str(row[\"device_id\"]))\n",
    "        data = row[[\"feature_1\", \"feature_2\", \"feature_3\"]].to_frame().T\n",
    "        return model.predict(data)[0]\n",
    "    \n",
    "    def predict(self, model_input):\n",
    "        return model_input.apply(self.predict_for_device, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "173f68cf-e9e6-4ed5-a2eb-651bad1c9d48",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<i18n value=\"da424f95-113f-4feb-a20c-6d0178d03bdb\"/>\n",
    "\n",
    "ここでは、このモデルの使い方を紹介します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1c5c49ee-b577-451d-aeaf-36bb549b21e5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "example_model = OriginDelegatingModel(device_to_model)\n",
    "example_model.predict(combined_df.toPandas().head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0d7524b9-343d-4dd3-a374-f510d0cbeae0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<i18n value=\"624309e5-7ba8-4968-92d4-3fe71e36375b\"/>\n",
    "\n",
    "ここから、1つのインスタンスからすべてのデバイスIDのモデルをサービングするために使用するモデルをログに記録し、登録することができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5cfe2300-1d18-4fa3-9300-a6c417f0b3ad",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "with mlflow.start_run():\n",
    "    model = OriginDelegatingModel(device_to_model)\n",
    "    mlflow.pyfunc.log_model(\"model\", python_model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0391766d-2914-4cb2-855b-82d1118c889a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "&copy; 2022 Databricks, Inc. All rights reserved.<br/>\n",
    "Apache, Apache Spark, Spark and the Spark logo are trademarks of the <a href=\"https://www.apache.org/\">Apache Software Foundation</a>.<br/>\n",
    "<br/>\n",
    "<a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | <a href=\"https://help.databricks.com/\">Support</a>"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "ML 13 - Training with Pandas Function API",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
