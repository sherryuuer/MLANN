{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3e2a43c7-25b0-4067-a0e0-330ccb7f5330",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n",
    "  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\" style=\"width: 600px\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "be59aa1e-4d8e-4e48-80a8-963a8b421ff8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<i18n value=\"b27f81af-5fb6-4526-b531-e438c0fda55e\"/>\n",
    "\n",
    "# MLflow\n",
    "\n",
    "<a href=\"https://mlflow.org/docs/latest/concepts.html\" target=\"_blank\">MLflow</a>は、この3つの核心的な問題を解決しようとしています。\n",
    "\n",
    "* 実験の追跡が難しい\n",
    "* コードの再現が難しい\n",
    "* モデルのパッケージングとデプロイの標準的な方法はない\n",
    "\n",
    "従来は、問題を調査する際に、構築した多数のモデルのそれぞれのパラメータとメトリクスを手作業で記録しておく必要がありました。このようなことはすぐに面倒になり、かなり時間がかかってしまいます。そこで、MLflowの出番となるわけです。\n",
    "\n",
    "MLflowはDatabricks Runtime for MLにプレインストールされています。\n",
    "\n",
    "## ![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) このレッスンでは以下を行います。<br>\n",
    "* MLflowを使った実験の追跡、メトリクスの記録、実行の比較など"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2e6172d6-b5c1-48f0-a679-1ee0d5e5bf2f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<i18n value=\"b7c8a0e0-649e-4814-8310-ae6225a57489\"/>\n",
    "\n",
    "<div><img src=\"https://files.training.databricks.com/images/eLearning/ML-Part-4/mlflow-tracking.png\" style=\"height: 400px; margin: 20px\"/></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "de6bddfe-970a-4c18-a86c-59f1d35dbc55",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run \"./Includes/Classroom-Setup\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "758aca84-68e2-49c4-98b3-c2435c52f20b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<i18n value=\"c1a29688-f50a-48cf-9163-ebcc381dfe38\"/>\n",
    "\n",
    "まずはSF Airbnb Datasetをロードしてみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ad0e53fb-9965-472b-83dd-c1a231db92ef",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "file_path = f\"{DA.paths.datasets}/airbnb/sf-listings/sf-listings-2019-03-06-clean.delta/\"\n",
    "airbnb_df = spark.read.format(\"delta\").load(file_path)\n",
    "\n",
    "train_df, test_df = airbnb_df.randomSplit([.8, .2], seed=42)\n",
    "print(train_df.cache().count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a015b1cc-355d-494f-8519-82bcf745ed21",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<i18n value=\"9ab8c080-9012-4f38-8b01-3846c1531a80\"/>\n",
    "\n",
    "### MLflow トラッキング (MLflow Tracking)\n",
    "\n",
    "MLflow トラッキングは、機械学習に特化したロギングAPIであり、学習に使うライブラリや環境に依存しないのが特徴です。 データサイエンス・コードの実行である**run**という概念を中心に構成されています。 Run は **experiment** に集約され、一つのexperimentが多数のrunを管理することが可能であり、MLflow サーバが多数のexperimentをホストされることができます。\n",
    "\n",
    "<a href=\"https://mlflow.org/docs/latest/python_api/mlflow.html#mlflow.set_experiment\" target=\"_blank\">mlflow.set_experiment()</a>で実験を指定することができますが、実験を指定しない場合は、自動的にこのノートブックのスコープで実験を設定されることになります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "42fa800d-6dbd-415c-bd01-bad581f6f4ef",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<i18n value=\"82786653-4926-4790-b867-c8ccb208b451\"/>\n",
    "\n",
    "### Runの追跡 (Track Runs)\n",
    "\n",
    "各Runには以下の情報を記録することができます。<br>\n",
    "\n",
    "- **Parameters：** 入力パラメータのキーと値のペア（ランダムフォレストモデルの木の数など）\n",
    "- **評価指標：** RMSE や ROC 曲線下の面積などの評価指標\n",
    "- **Artifact：** 任意の形式の出力ファイル 画像、モデルのpickleファイル、データファイルが含まれます。\n",
    "- **ソース：** 実験を実行したコード\n",
    "\n",
    "**注**:Sparkモデルについては、MLflowはPipelineModelsのみロギングすることができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8c67f908-b98b-411d-9f31-4c0c5e9c1bcd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.spark\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "with mlflow.start_run(run_name=\"LR-Single-Feature\") as run:\n",
    "    # Define pipeline\n",
    "    vec_assembler = VectorAssembler(inputCols=[\"bedrooms\"], outputCol=\"features\")\n",
    "    lr = LinearRegression(featuresCol=\"features\", labelCol=\"price\")\n",
    "    pipeline = Pipeline(stages=[vec_assembler, lr])\n",
    "    pipeline_model = pipeline.fit(train_df)\n",
    "\n",
    "    # Log parameters\n",
    "    mlflow.log_param(\"label\", \"price\")\n",
    "    mlflow.log_param(\"features\", \"bedrooms\")\n",
    "\n",
    "    # Log model\n",
    "    mlflow.spark.log_model(pipeline_model, \"model\", input_example=train_df.limit(5).toPandas()) \n",
    "\n",
    "    # Evaluate predictions\n",
    "    pred_df = pipeline_model.transform(test_df)\n",
    "    regression_evaluator = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"price\", metricName=\"rmse\")\n",
    "    rmse = regression_evaluator.evaluate(pred_df)\n",
    "\n",
    "    # Log metrics\n",
    "    mlflow.log_metric(\"rmse\", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5cd061dc-ce78-40c5-8275-be3f9b7a25f5",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<i18n value=\"44bc7cac-de4a-47e7-bfff-6d2eb58172cd\"/>\n",
    "\n",
    "これで、すべて完了です。\n",
    "\n",
    "ほかの2つの線形回帰モデルを作成して、実行結果を比較してみましょう。\n",
    "\n",
    "**質問**：他のRunのRMSEを覚えていますか？\n",
    "\n",
    "次に、全ての特徴量を使用して線形回帰モデルを構築します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9d2cc965-b273-4485-9e92-df74b085aef7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import RFormula\n",
    "\n",
    "with mlflow.start_run(run_name=\"LR-All-Features\") as run:\n",
    "    # Create pipeline\n",
    "    r_formula = RFormula(formula=\"price ~ .\", featuresCol=\"features\", labelCol=\"price\", handleInvalid=\"skip\")\n",
    "    lr = LinearRegression(labelCol=\"price\", featuresCol=\"features\")\n",
    "    pipeline = Pipeline(stages=[r_formula, lr])\n",
    "    pipeline_model = pipeline.fit(train_df)\n",
    "\n",
    "    # Log pipeline\n",
    "    mlflow.spark.log_model(pipeline_model, \"model\", input_example=train_df.limit(5).toPandas())\n",
    "\n",
    "    # Log parameter\n",
    "    mlflow.log_param(\"label\", \"price\")\n",
    "    mlflow.log_param(\"features\", \"all_features\")\n",
    "\n",
    "    # Create predictions and metrics\n",
    "    pred_df = pipeline_model.transform(test_df)\n",
    "    regression_evaluator = RegressionEvaluator(labelCol=\"price\", predictionCol=\"prediction\")\n",
    "    rmse = regression_evaluator.setMetricName(\"rmse\").evaluate(pred_df)\n",
    "    r2 = regression_evaluator.setMetricName(\"r2\").evaluate(pred_df)\n",
    "\n",
    "    # Log both metrics\n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "    mlflow.log_metric(\"r2\", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2da7e491-874c-4f24-b05e-c1328173e6bc",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<i18n value=\"70188282-8d26-427d-b374-954e9a058000\"/>\n",
    "\n",
    "最後に、対数正規分布であるので、価格の対数を予測する線形回帰モデルを構築します。\n",
    "\n",
    "また、ログの正規分布のヒストグラムを作り、アーティファクトとして記録する練習をします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "897d9874-0a81-4ab0-b3ba-c376e3022bec",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, log, exp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "with mlflow.start_run(run_name=\"LR-Log-Price\") as run:\n",
    "    # Take log of price\n",
    "    log_train_df = train_df.withColumn(\"log_price\", log(col(\"price\")))\n",
    "    log_test_df = test_df.withColumn(\"log_price\", log(col(\"price\")))\n",
    "\n",
    "    # Log parameter\n",
    "    mlflow.log_param(\"label\", \"log_price\")\n",
    "    mlflow.log_param(\"features\", \"all_features\")\n",
    "\n",
    "    # Create pipeline\n",
    "    r_formula = RFormula(formula=\"log_price ~ . - price\", featuresCol=\"features\", labelCol=\"log_price\", handleInvalid=\"skip\")  \n",
    "    lr = LinearRegression(labelCol=\"log_price\", predictionCol=\"log_prediction\")\n",
    "    pipeline = Pipeline(stages=[r_formula, lr])\n",
    "    pipeline_model = pipeline.fit(log_train_df)\n",
    "\n",
    "    # Log model\n",
    "    mlflow.spark.log_model(pipeline_model, \"log-model\", input_example=log_train_df.limit(5).toPandas())\n",
    "\n",
    "    # Make predictions\n",
    "    pred_df = pipeline_model.transform(log_test_df)\n",
    "    exp_df = pred_df.withColumn(\"prediction\", exp(col(\"log_prediction\")))\n",
    "\n",
    "    # Evaluate predictions\n",
    "    rmse = regression_evaluator.setMetricName(\"rmse\").evaluate(exp_df)\n",
    "    r2 = regression_evaluator.setMetricName(\"r2\").evaluate(exp_df)\n",
    "\n",
    "    # Log metrics\n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "    mlflow.log_metric(\"r2\", r2)\n",
    "\n",
    "    # Log artifact\n",
    "    plt.clf()\n",
    "\n",
    "    log_train_df.toPandas().hist(column=\"log_price\", bins=100)\n",
    "    fig = plt.gcf()\n",
    "    mlflow.log_figure(fig, f\"{DA.username}_log_normal.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "07cf69a4-d7bb-4cef-ae91-3f62ffd9faa8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<i18n value=\"66785d5e-e1a7-4896-a8a9-5bfcd18acc5c\"/>\n",
    "\n",
    "それです！\n",
    "\n",
    "では、MLflowを使ってモデルのパフォーマンスを比較してみましょう。過去のRunの照会はプログラムとMLflow UIの2つの方法があります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "80bb49d5-737d-4f83-92ac-01d36bead7a1",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<i18n value=\"0b1a68e1-bd5d-4f78-a452-90c7ebcdef39\"/>\n",
    "\n",
    "### 過去のRunを照会する (Querying Past Runs)\n",
    "\n",
    "このデータをPythonで利用するために、プログラム上で過去の実行結果を照会することができます。 これを行うために **`MlflowClient`** オブジェクトを使用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6c608bcd-1af2-467c-ae02-ba7cf244bea2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "client = MlflowClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d708b31a-c9d6-446b-ab45-3e11137ba68a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "client.list_experiments()\n",
    "# client.list_registered_experiments()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e77a5a99-54dc-434f-b9b9-3c51b2f2c04c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<i18n value=\"dcd771b2-d4ed-4e9c-81e5-5a3f8380981f\"/>\n",
    "\n",
    "また、<a href=\"https://mlflow.org/docs/latest/search-syntax.html\" target=\"_blank\">search_runs</a> を使えば、指定した実験に対するすべてのランを検索することができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c2b672f7-e943-4883-a630-d39c266a9a38",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "experiment_id = run.info.experiment_id\n",
    "runs_df = mlflow.search_runs(experiment_id)\n",
    "\n",
    "display(runs_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c357010a-954a-46f0-b248-e3b76c5aae43",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<i18n value=\"68990866-b084-40c1-beee-5c747a36b918\"/>\n",
    "\n",
    "最後のランのメトリクスを確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f1976081-cfb6-4a8f-8578-3965245052e1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "runs = client.search_runs(experiment_id, order_by=[\"attributes.start_time desc\"], max_results=1)\n",
    "runs[0].data.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "061c4e12-18f4-4be6-97f2-3b20b57ee39f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "runs[0].info.run_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e58720c9-b4a8-4f5e-a07c-cd6b7bf8c592",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<i18n value=\"cfbbd060-6380-444f-ba88-248e10a56559\"/>\n",
    "\n",
    "UIで結果を確認します。 以下をご確認ください：\n",
    "\n",
    "1. **`Experiment ID`**\n",
    "1. アーティファクトの保存場所。 アーティファクトがDBFSに保存される場所です。\n",
    "1. Runが実行された時間です。**ランの詳細情報を見るには、これをクリックしてください。**\n",
    "1. Runを実行したコード。\n",
    "\n",
    "\n",
    "実行時間をクリックした後、下記をご覧ください：\n",
    "\n",
    "1. Run IDは、上記で表示したものと一致します。\n",
    "1. 保存したモデルには、モデルのpickleファイル、Conda環境、 **`MLmodel`** ファイルが含まれています。\n",
    "\n",
    "なお、「Notes」タブでメモを追加することで、モデルに関する重要な情報を記録することができます。\n",
    "\n",
    "対数正規分布のRunをクリックすると、「アーティファクト」にヒストグラムが保存されることを確認します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "68f02604-5c4a-4d5a-a675-dfe77e751ad0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<i18n value=\"63ca7584-2a86-421b-a57e-13d48db8a75d\"/>\n",
    "\n",
    "### 保存されたモデルのロード (Load Saved Model)\n",
    "\n",
    "<a href=\"https://www.mlflow.org/docs/latest/python_api/mlflow.spark.html\" target=\"_blank\">ロード</a>という練習をしてみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ac74b288-a4a5-4341-91e2-944e62e8f5b9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model_path = f\"runs:/{run.info.run_id}/log-model\"\n",
    "loaded_model = mlflow.spark.load_model(model_path)\n",
    "\n",
    "display(loaded_model.transform(test_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f67f60fc-3987-44f0-bf1c-18633f51e3c8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "&copy; 2022 Databricks, Inc. All rights reserved.<br/>\n",
    "Apache, Apache Spark, Spark and the Spark logo are trademarks of the <a href=\"https://www.apache.org/\">Apache Software Foundation</a>.<br/>\n",
    "<br/>\n",
    "<a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | <a href=\"https://help.databricks.com/\">Support</a>"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "ML 04 - MLflow Tracking",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
