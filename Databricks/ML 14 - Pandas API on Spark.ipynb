{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "884ca0b3-a123-4e33-8e01-2b4853a5464e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n",
    "  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\" style=\"width: 600px\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4e870bdf-cb1c-4491-9053-fb061066511a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<i18n value=\"c311be95-77f9-477b-93a5-c9289b3dedb6\"/>\n",
    "\n",
    "# SparkにおけるPandas API (Pandas API on Spark)\n",
    "\n",
    "pandas API on Sparkプロジェクトは、Apache Sparkにおけるpandas DataFrame APIを実装することにより、データサイエンティストがビッグデータを扱う際の生産性を高めることを目的としています。2つのエコシステムを使い慣れたAPIに統一することで、pandas API on Sparkは小規模データと大規模データの間のシームレスな切り替えを提供します。\n",
    "\n",
    "PySpark 3.2にマージされた<a href=\"https://github.com/databricks/koalas\" target=\"_blank\">Koalas</a>プロジェクトについてご存知の方もいるかもしれません。Apache Spark 3.2以降では、スタンドアローンのKoalasプロジェクトがメンテナンスモードに入ったため、PySparkを直接ご利用ください。こちらの<a href=\"https://databricks.com/blog/2021/10/04/pandas-api-on-upcoming-apache-spark-3-2.html\" target=\"_blank\">ブログ記事</a>をご覧ください。\n",
    "\n",
    "## ![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) このレッスンでは次を行います:<br>\n",
    "- Sparkのpandas APIと普通のpandas APIとの類似性を確認します。\n",
    "- SparkとPySparkのpandas APIで同じDataFrameの操作を行う場合の構文の違いを理解します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "39408b53-df76-4439-8084-7192fc4437d6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<i18n value=\"d711990a-af32-4357-b710-d2db434e4f15\"/>\n",
    "\n",
    "<div style=\"img align: center; line-height:0; padding-top:9px;\">\n",
    "  <img src=\"https://files.training.databricks.com/images/301/31gb.png\" width=\"900\"/>\n",
    "</div>\n",
    "\n",
    "<div style=\"img align: center; line-height:0; padding-top:9px;\">\n",
    "  <img src=\"https://files.training.databricks.com/images/301/95gb.png\" width=\"900\"/>\n",
    "</div>\n",
    "\n",
    "**Pandas** DataFrames は ミュータブル(変更可能) で、強制的に評価され、行の順序を維持します。これらは1台のマシンに限定され、a)に示すようにデータセットが小さい場合に非常に高い性能を出します。\n",
    "\n",
    "**Spark** DataFrameは、分散的、遅延評価され、不変であり、行の順序を維持しません。b)とc)に示したように、大規模データの場合の性能は非常に高いです。\n",
    "\n",
    "**pandas API on Spark**は、pandas APIとSparkの性能上の利点という、両者の利点を提供します。しかし、Sparkでネイティブにソリューションを実装するのに比べれば、速度は劣ります。以下にその理由を説明します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ea32c5de-ce5f-431f-b2e6-e882c8ffd91e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<i18n value=\"c3080510-c8d9-4020-9910-37199f0ad5de\"/>\n",
    "\n",
    "## InternalFrame\n",
    "\n",
    "InternalFrameは、現在のSpark DataFrameと内部の不変のメタデータを保持します。\n",
    "\n",
    "Pandas API on Sparkのカラム名からSparkのカラム名へのマッピング、およびpandas API on Sparkのインデックス名からSparkのカラム名へのマッピングを管理します。\n",
    "\n",
    "ユーザが何らかのAPIを呼び出すと、Sparkのpandas API DataFrameがInternalFrameのSpark DataFrameとメタデータを更新します。現在のInternalFrameを新しい状態で作成またはコピーし、新しいpandas API on Spark DataFrameを返します。\n",
    "\n",
    "<div style=\"img align: center; line-height:0; padding-top:9px;\">\n",
    "  <img src=\"https://files.training.databricks.com/images/301/InternalFramePs.png\" width=\"900\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c520375c-7b4c-4026-829a-e1d7a8d7b387",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<i18n value=\"785ed714-6726-40d5-b7fb-c63c094e568e\"/>\n",
    "\n",
    "## InternalFrameメタデータのみ更新 (InternalFrame Metadata Updates Only)\n",
    "\n",
    "Spark DataFrameではなく、メタデータのみを更新する場合は、以下のような新しい構造になります。\n",
    "\n",
    "<div style=\"img align: center; line-height:0; padding-top:9px;\">\n",
    "  <img src=\"https://files.training.databricks.com/images/301/InternalFrameMetadataPs.png\" width=\"900\"/>.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d1935b3b-5562-4e5e-8693-976cd66a57ac",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<i18n value=\"e6d7a47f-a4c8-4178-bc70-62c2ac6764d5\"/>\n",
    "\n",
    "## InternalFrame inplace更新 (InternalFrame Inplace Updates)\n",
    "\n",
    "一方、pandas API on Spark DataFrameは、新しいDataFrameを返すのではなく内部の状態を更新することがあります。例えば、引数inplace=Trueを与えると、新しい構造は以下のようになります。\n",
    "\n",
    "<div style=\"img align: center; line-height:0; padding-top:9px;\">\n",
    "  <img src=\"https://files.training.databricks.com/images/301/InternalFrameUpdate.png\" width=\"900\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "061a1c60-32a8-4648-ac5d-b00e98dcc20b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<i18n value=\"23a2fc6d-1360-4e41-beab-b1fe8e23aac3\"/>\n",
    "\n",
    "### データセットの読み込み (Read in the dataset)\n",
    "\n",
    "* PySpark\n",
    "* Pandas\n",
    "* Pandas API on Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8d0c9111-aec4-45eb-aa41-3fb2afaa04af",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run \"./Includes/Classroom-Setup\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e0c41d36-0172-438e-b86f-0383331003a7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<i18n value=\"1be64dea-9d63-476d-a7d6-9f6fa4ccd784\"/>\n",
    "\n",
    "PySparkでParquetを読み込みます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e0c5ed28-92cb-498b-a271-c9da479fbeb3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark_df = spark.read.parquet(f\"{DA.paths.datasets}/airbnb/sf-listings/sf-listings-2019-03-06-clean.parquet/\")\n",
    "display(spark_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4b42c784-46a2-46ca-a920-44cfeb256b25",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<i18n value=\"00b99bdc-e4d1-44d2-b117-ae2cd97d0490\"/>\n",
    "\n",
    "PandasでをParquetを読み込みます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b16c8441-55a5-4f52-91f6-b12b912e932e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pandas_df = pd.read_parquet(f\"{DA.paths.datasets.replace('dbfs:/', '/dbfs/')}/airbnb/sf-listings/sf-listings-2019-03-06-clean.parquet/\")\n",
    "pandas_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "365569b9-1bb1-4d22-abc7-d92011c299b6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<i18n value=\"e75a3ba6-98f6-4b39-aecb-345109cb2ce9\"/>\n",
    "\n",
    "Pandas API on SparkでParquetを読み込みます。Pandas API on Sparkが、pandasのようにインデックスカラムを作成します。\n",
    "\n",
    "Pandas API on Spark はDeltaからの読み込み(**`read_delta`**)もサポートしていますが、pandasはまだサポートしていません。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0ad054d6-69ed-4318-9148-b801420a9c48",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pyspark.pandas as ps\n",
    "\n",
    "df = ps.read_parquet(f\"{DA.paths.datasets}/airbnb/sf-listings/sf-listings-2019-03-06-clean.parquet/\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "50921974-eb84-43dd-ad12-ff42577b2be7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<i18n value=\"f099c73b-0bd8-4ff1-a12e-578ffb0cb152\"/>\n",
    "\n",
    "### <a href=\"https://koalas.readthedocs.io/en/latest/user_guide/options.html#default-index-type\" target=\"_blank\">インデックスの種類</a>\n",
    "\n",
    "![](https://files.training.databricks.com/images/301/koalas_index.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cba56c0a-b3b7-4e36-9c8c-d228de412bf4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ps.set_option(\"compute.default_index_type\", \"distributed-sequence\")\n",
    "df_dist_sequence = ps.read_parquet(f\"{DA.paths.datasets}/airbnb/sf-listings/sf-listings-2019-03-06-clean.parquet/\")\n",
    "df_dist_sequence.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d1fa6d98-c757-4995-85f8-4d9be7258b72",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<i18n value=\"07b3f029-f81b-442f-8cdd-cb2d29033a35\"/>\n",
    "\n",
    "### Spark DataFrameとpandas API on Spark DataFrameの変換 (Converting to pandas API on Spark DataFrame to/from Spark DataFrame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5d88c650-856e-4b48-9c08-ffb14dd58d13",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<i18n value=\"ed25204e-2822-4694-b3b3-968ea8ef7343\"/>\n",
    "\n",
    "PySpark DataFrameからpandas API on Spark DataFrame を作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "516612a8-81ce-4fbf-aa80-b24b34bf4017",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = ps.DataFrame(spark_df)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c7091f78-ba19-44fb-85f6-2d1cd119e639",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<i18n value=\"a41480c7-1787-4bd6-a4c3-c85552a5f762\"/>\n",
    "\n",
    "PySpark DataFrameからpandas API on Spark DataFrameを作成する代替手段"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "47801b33-b3c4-45bd-8d7f-96f62a41a245",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark_df.to_pandas_on_spark()\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6ea550b0-d18a-4d86-b70b-498dd17ccfc4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<i18n value=\"5abf965b-2f69-469e-a0cf-ba8ffd714764\"/>\n",
    "\n",
    "Pandas API on Spark DataFrameからSpark DataFrameへ変換します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1eec5508-a8ee-4000-8c4b-4ec486ffe72d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(df.to_spark())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "00675ddc-558a-4a27-a738-39f2d438297e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<i18n value=\"480e9e60-9286-4f4c-9db3-b650b32cb7ce\"/>\n",
    "\n",
    "### 値のカウント (Value Counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "320b2b10-9eff-4c08-8430-b83c38f1d23a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<i18n value=\"99f93d32-d09d-4fea-9ac9-57099eb2c819\"/>\n",
    "\n",
    "PySparkで異なるプロパティタイプをカウントします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "03b51ed4-55f0-46c3-b86d-883345413f2c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(spark_df.groupby(\"property_type\").count().orderBy(\"count\", ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "655c554d-2ee1-4a2f-b4c4-d9cc727b5159",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<i18n value=\"150b6a18-123d-431a-84b1-ad2d2b7beae2\"/>\n",
    "\n",
    "Pandas API on Sparkで異なるプロパティタイプをカウントします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "df253d58-35ce-4b81-b781-87d54594cd37",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df[\"property_type\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "403cc4e5-5763-4cd0-8c39-9f3692f2b770",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<i18n value=\"767f19b5-137f-4b33-9ef4-e5bb48603299\"/>\n",
    "\n",
    "### 可視化\n",
    "\n",
    "Pandas API on Sparkでは、可視化の種類に応じて、プロットの実行方法が最適化されています。\n",
    "<br><br>\n",
    "\n",
    "![](https://files.training.databricks.com/images/301/ps_plotting.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d9e532e8-0654-4c26-bd0e-efef3aa13fd9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.plot(kind=\"hist\", x=\"bedrooms\", y=\"price\", bins=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f4651165-abcb-449d-8b4e-e253c65d7cf8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<i18n value=\"6b70f1df-dfe1-43de-aeec-5541b036927c\"/>\n",
    "\n",
    "### pandas API on Spark DataFramesをSQLで操作 (SQL on pandas API on Spark DataFrames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "24e11b2a-53cb-430b-b92d-69a3ff04b87a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ps.sql(\"SELECT * FROM {df} limit 5\", df=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8ce00536-7fb7-41f6-8d63-57cb17787486",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<i18n value=\"7345361b-e6c4-4ce3-9ba4-8f132c8c8df2\"/>\n",
    "\n",
    "### 興味深い事実\n",
    "\n",
    "* Pandas API on Sparkを使えば、Delta Tablesから読み込んだり、ファイルのディレクトリから読み込んだりすることができます。\n",
    "* Pandas API on Spark の DF が <1000 (デフォルト) の場合、pandas API on Spark は pandas をショートカットとして使用します - 閾値は **`compute.shortcut_limit`** で調整することが可能です。\n",
    "* 棒グラフを作成した場合、上位n行のみが使用されます - これは **`plotting.max_rows`** を使用して調整することができます。\n",
    "* **`.apply`** <a href=\"https://koalas.readthedocs.io/en/latest/reference/api/databricks.koalas.DataFrame.apply.html#databricks.koalas.DataFrame.apply\" target=\"_blank\">文書</a> と 戻り値のヒントを利用する方法はpandas UDF に似ています。\n",
    "* 実行計画の確認方法、pandas API on Spark DFのキャッシュ方法（すぐに直感的に理解できるものではありません。）\n",
    "* コアラは有袋類で、最高時速は30km/h(20 mph)です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4c1f96e7-bcbe-4b7d-9f8f-d7a9b6a1882d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "&copy; 2022 Databricks, Inc. All rights reserved.<br/>\n",
    "Apache, Apache Spark, Spark and the Spark logo are trademarks of the <a href=\"https://www.apache.org/\">Apache Software Foundation</a>.<br/>\n",
    "<br/>\n",
    "<a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | <a href=\"https://help.databricks.com/\">Support</a>"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "ML 14 - Pandas API on Spark",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
